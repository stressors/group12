
import streamlit as st
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import os
from io import BytesIO  
import base64

# ===================== CONFIG & THEME =====================

st.set_page_config(
    page_title="ğŸ§® Matrix Transformations in Image Processing",
    layout="wide"
)
# ---------- VIDEO BACKGROUND (HTML langsung) ----------
def set_video_background(video_path: str):
    """Set an mp4 video as full-screen background using HTML/CSS."""
    if not os.path.exists(video_path):
        st.warning(f"Video background tidak ditemukan: {video_path}")
        return

    with open(video_path, "rb") as f:
        data = f.read()
    b64 = base64.b64encode(data).decode("utf-8")
    video_data_url = f"data:video/mp4;base64,{b64}"

    html = """
        <style>
        .video-bg {{
            position: fixed;
            right: 0;
            bottom: 0;
            min-width: 100%;
            min-height: 100%;
            width: auto;
            height: auto;
            z-index: -1;
            object-fit: cover;
        }}
        .stApp {{
            background: transparent !important;
        }}
        </style>
        <video class="video-bg" autoplay muted loop playsinline>
            <source src="{video_data_url}" type="video/mp4">
        </video>
        """.format(video_data_url=video_data_url)
    st.markdown(html, unsafe_allow_html=True)

set_video_background("assets/background.mp4")

# ----- Initialize Session State -----
if "language" not in st.session_state:
    st.session_state["language"] = "id"
if "original_img" not in st.session_state:
    st.session_state.original_img = None
if "geo_transform" not in st.session_state:
    st.session_state["geo_transform"] = None
if "image_filter" not in st.session_state:
    st.session_state["image_filter"] = None

# ===================== TRANSLATIONS =====================

translations = {
    "id": {
        "title": "ğŸ”¢ Operasi Matriks untuk Editing Visual",
        "subtitle": "ğŸ¯ Eksplorasi langsung perubahan matriks 2D dan penyesuaian gambar",
        "app_goal": "ğŸ¯ **Tujuan aplikasi:** Penjelasan praktis yang menunjukkan fungsi perubahan matriks 2D dan penyaringan gambar pada foto menggunakan ide aljabar linier.",
        "features": "- â†©ï¸ Perubahan: memindah, mengukur, memutar, memiringkan, membalik\n- ğŸ§½ Penyesuaian: menghaluskan, memfokuskan, menemukan garis, menghilangkan latar, mengubah ke hitam putih, menyesuaikan cahaya & bayangan",
        "concept_1_title": "### ğŸŒ€ Perubahan Matriks Dua Dimensi",
        "concept_1_text1": "Gambar datar adalah sekumpulan titik \\((x, y)\\) yang bisa diubah lewat tindakan lurus seperti memindah, mengukur, memutar, memiringkan, dan membalik, ditampilkan oleh matriks 2Ã—2 atau 3Ã—3 (titik seragam).",
        "concept_1_text2": "Menggunakan matriks ini pada posisi titik menggesernya: mengukur mengubah skala, memutar berputar di tengah, memiringkan membuat miring, dan membalik membalik pandangan di garis tertentu.",
        "concept_2_title": "### ğŸ“Š Penyesuaian Gambar (Pencampuran)",
        "concept_2_text1": "Penyesuaian menggunakan kisi kecil (matriks pencampuran) yang meluncur di gambar; di setiap tempat, ia membuat nilai titik baru dari total kali kisi dengan titik sekitar.",
        "concept_2_text2": "Kisi dengan angka baik seragam membuat pandangan lebih halus atau kabur, sementara kisi dengan tengah baik kuat dan sekitar buruk membuat lebih tajam dan menonjolkan tepi.",
        "concept_3_title": "### ğŸ² Mengapa Praktis?",
        "concept_3_text1": "Aplikasi ini praktis karena pengguna bisa menyetel pengaturan (seperti derajat putar, faktor ukur, kekuatan miring, jenis kisi untuk halus atau fokus, dll.) dan langsung lihat perubahan di gambar. âœ¨",
        "concept_3_text2": "Ini menghubungkan struktur kisi atau matriks dengan hasil visual, membuat gagasan seperti perubahan lurus dan pencampuran lebih gampang dipahami secara alami.",
        "quick_concepts": "#### ğŸ“ Ide Utama",
        "quick_concepts_text": "- â†©ï¸ Perubahan 2D: geser posisi titik (memindah, mengukur, memutar, memiringkan, membalik).\n- ğŸ“Š Pencampuran: kisi kecil meluncur di gambar untuk membuat nilai titik baru.",
        "upload_title": "### ğŸ“· Tambah Foto",
        "upload_label": "Tambah foto di sini (PNG/JPG/JPEG) ğŸ“‚",
        "upload_success": "âœ… Foto ditambah dengan baik!",
        "upload_preview": "ğŸ“· Tampilan Foto Awal",
        "upload_info": "â¬†ï¸ Tolong tambah foto dulu untuk pakai alat di bawah.",
        "tools_title": "### ğŸ”§ Alat Editing Foto",
        "tools_subtitle": "ğŸ›ï¸ Pilih kotak di bawah untuk buka setelan perubahan atau penyesuaian.",
        "geo_title": "#### ğŸ”„ Perubahan Bentuk",
        "geo_desc": "Perubahan bentuk mengubah posisi titik, ukuran, dan arah menggunakan tindakan lurus (matriks).",
        "btn_translation": "â†”ï¸ Pindah",
        "btn_scaling": "ğŸ“ Ukuran",
        "btn_rotation": "ğŸ”„ Putar",
        "btn_shearing": "ğŸ“ Miring",
        "btn_reflection": "ğŸª Cermin",
        "geo_info": "ğŸ”” Tolong tambah foto dulu untuk coba perubahan.",
        "trans_settings": "**â†”ï¸ Setelan Pindah**",
        "trans_dx": "dx (geser samping)",
        "trans_dy": "dy (geser atas-bawah)",
        "btn_apply": "Pakai",
        "trans_result": "Hasil Pindah",
        "scale_settings": "**ğŸ“ Setelan Ukuran**",
        "scale_x": "Ukuran X",
        "scale_y": "Ukuran Y",
        "scale_result": "Hasil Ukuran",
        "rot_settings": "**ğŸ”„ Setelan Putar**",
        "rot_angle": "Sudut putar (derajat)",
        "rot_result": "Hasil Putar",
        "shear_settings": "**ğŸ“ Setelan Miring**",
        "shear_x": "Faktor miring X",
        "shear_y": "Faktor miring Y",
        "shear_result": "Hasil Miring",
        "refl_settings": "**ğŸª Setelan Cermin**",
        "refl_axis": "Garis cermin",
        "refl_result": "Hasil Cermin",
        "hist_title": "#### ğŸ“ˆ Bagan Foto",
        "hist_desc": "Bagan menampilkan sebaran kekuatan titik (redupâ€“terang), berguna untuk periksa cahaya dan bayangan.",
        "btn_histogram": "Tampilkan Bagan ğŸ“ˆ",
        "hist_warning": "Tolong tambah foto dulu untuk tampilkan bagan.",
        "filter_title": "#### ğŸ”§ Penyesuaian Foto",
        "filter_desc": "Penyesuaian mengubah nilai titik berdasarkan tetangga (pencampuran) untuk lakukan halus, fokus, temukan garis, hilangkan latar, dan lain.",
        "btn_blur": "ğŸ”² Halus",
        "btn_sharpen": "âœ¨ Fokus",
        "btn_background": "ğŸ¯ Latar",
        "btn_grayscale": "âš« Hitam Putih",
        "btn_edge": "ğŸ” Garis",
        "btn_brightness": "â˜€ï¸ Cahaya",
        "filter_info": "ğŸ”” Tolong tambah foto dulu untuk pakai penyesuaian.",
        "blur_settings": "**ğŸ”² Setelan Penyesuaian Halus**",
        "blur_kernel": "Ukuran kisi",
        "blur_result": "Hasil Halus",
        "sharpen_settings": "**âœ¨ Setelan Penyesuaian Fokus**",
        "sharpen_desc": "Tingkatkan rincian dan garis di foto.",
        "sharpen_result": "Hasil Fokus",
        "bg_settings": "**ğŸ¯ Setelan Hilangkan Latar**",
        "bg_method": "Cara (demo pakai HSV saja sekarang)",
        "bg_result": "Hasil Hilangkan Latar",
        "gray_settings": "**âš« Setelan Ubah Hitam Putih**",
        "gray_desc": "Ubah foto ke hitam putih (abu-abu).",
        "gray_result": "Hasil Hitam Putih",
        "edge_settings": "**ğŸ” Setelan Temukan Garis**",
        "edge_method": "Cara garis",
        "edge_result": "Foto Garis",
        "bright_settings": "**â˜€ï¸ Setelan Cahaya & Bayangan**",
        "bright_brightness": "Cahaya",
        "bright_contrast": "Bayangan",
        "bright_result": "Hasil Cahaya/Bayangan",
        "team_title": "### ğŸ‘¥ Orang Kelompok",
        "team_subtitle": "Kelompok 12 â€“ Orang dan Tugas",
        "team_sid": "ID:",
        "team_role": "Tugas:",
        "team_contribution": "Kontribusi:",
        "upload_method_title": "### Cara Penguploadan Foto",
        "upload_method_text": "**Langkah-langkah untuk mengupload foto:**\n1. Klik tombol **\"Tambah foto di sini (PNG/JPG/JPEG) ğŸ“‚\"** yang terletak di bagian atas halaman.\n2. Pilih file gambar dari perangkat Anda (format yang didukung: PNG, JPG, atau JPEG).\n3. Tunggu hingga gambar berhasil diupload dan ditampilkan di layar.\n4. Jika berhasil, Anda akan melihat pesan konfirmasi dan preview gambar awal.\n5. Sekarang Anda dapat menggunakan alat editing di kolom kiri (transformasi geometris) dan kanan (penyesuaian gambar).",
        "team_group": "Kelompok:",
        "axis_x": "Garis-X",
        "axis_y": "Garis-Y",
        "axis_diag": "Silang",
        "dark_mode": "Gaya Malam",
        "light_mode": "Gaya Siang",
    },
    "en": {
        "title": "ğŸ”¢ Matrix Operations for Visual Editing",
        "subtitle": "ğŸ¯ Live exploration of 2D matrix changes and picture adjustments",
        "app_goal": "ğŸ¯ **Goal:** A hands-on exploration showing how 2D matrix changes and picture adjustments affect visuals through linear algebra ideas.",
        "features": "- â†©ï¸ Changes: moving, sizing, turning, slanting, flipping\n- ğŸ§½ Adjustments: smoothing, focusing, outline spotting, backdrop clearing, turning to monochrome, tweaking light & shade",
        "concept_1_title": "### ğŸŒ€ 2D Matrix Changes",
        "concept_1_text1": "A flat image is a group of spots \\((x, y)\\) that get moved by straight-line actions like moving, sizing, turning, slanting, and flipping, shown by 2Ã—2 or 3Ã—3 matrices (uniform spots).",
        "concept_1_text2": "Using these matrices on spot places shifts them: sizing changes the scale, turning spins the view around its middle, slanting makes it lean, and flipping reverses the view on a chosen line.",
        "concept_2_title": "### ğŸ“Š Picture Adjustments (Mixing)",
        "concept_2_text1": "Adjusting uses a tiny grid (mixing matrix) that glides over the image; at each spot, it makes a fresh spot value by adding up the grid times nearby spots.",
        "concept_2_text2": "Grids with even good numbers make the view softer or fuzzy, while grids with a big good middle and bad sides make it sharper and highlight edges.",
        "concept_3_title": "### ğŸ² Why Hands-On?",
        "concept_3_text1": "The app is hands-on since users can tweak settings (such as turn degrees, size rates, slant strengths, grid kinds for smooth or focus, etc.) and right away see the changes on the view. âœ¨",
        "concept_3_text2": "It links the grid or matrix setup to seen effects, making thoughts like straight changes and mixing simpler to grasp naturally.",
        "quick_concepts": "#### ğŸ“ Key Ideas",
        "quick_concepts_text": "- â†©ï¸ 2D Changes: shift spot places (moving, sizing, turning, slanting, flipping).\n- ğŸ“Š Mixing: a tiny grid gliding over the image to make fresh spot values.",
        "upload_title": "### ğŸ“· Add Picture",
        "upload_label": "Add a picture here (PNG/JPG/JPEG) ğŸ“‚",
        "upload_success": "âœ… Picture added well!",
        "upload_preview": "ğŸ“· Starting Picture View",
        "upload_info": "â¬†ï¸ Kindly add a picture first to use the tools below.",
        "tools_title": "### ğŸ”§ Picture Editing Tools",
        "tools_subtitle": "ğŸ›ï¸ Pick a box below to open change or adjust settings.",
        "geo_title": "#### ğŸ”„ Shape Changes",
        "geo_desc": "Shape changes alter the spot position, size, and direction using straight actions (matrices).",
        "btn_translation": "â†”ï¸ Move",
        "btn_scaling": "ğŸ“ Size",
        "btn_rotation": "ğŸ”„ Turn",
        "btn_shearing": "ğŸ“ Slant",
        "btn_reflection": "ğŸª Mirror",
        "geo_info": "ğŸ”” Kindly add a picture first to try changes.",
        "trans_settings": "**â†”ï¸ Move Settings**",
        "trans_dx": "dx (side move)",
        "trans_dy": "dy (up-down move)",
        "btn_apply": "Use",
        "trans_result": "Move Outcome",
        "scale_settings": "**ğŸ“ Size Settings**",
        "scale_x": "Size X",
        "scale_y": "Size Y",
        "scale_result": "Size Outcome",
        "rot_settings": "**ğŸ”„ Turn Settings**",
        "rot_angle": "Turn angle (degrees)",
        "rot_result": "Turn Outcome",
        "shear_settings": "**ğŸ“ Slant Settings**",
        "shear_x": "Slant factor X",
        "shear_y": "Slant factor Y",
        "shear_result": "Slant Outcome",
        "refl_settings": "**ğŸª Mirror Settings**",
        "refl_axis": "Mirror line",
        "refl_result": "Mirror Outcome",
        "hist_title": "#### ğŸ“ˆ Picture Chart",
        "hist_desc": "The chart displays the spread of spot strengths (dimâ€“bright), handy for checking light and shade.",
        "btn_histogram": "Show Chart ğŸ“ˆ",
        "hist_warning": "Kindly add a picture first to show the chart.",
        "filter_title": "#### ğŸ”§ Picture Adjustments",
        "filter_desc": "Adjustments change spot values based on neighbors (mixing) to do smooth, focus, outline finding, backdrop removal, and more.",
        "btn_blur": "ğŸ”² Smooth",
        "btn_sharpen": "âœ¨ Focus",
        "btn_background": "ğŸ¯ Backdrop",
        "btn_grayscale": "âš« Monochrome",
        "btn_edge": "ğŸ” Outline",
        "btn_brightness": "â˜€ï¸ Light",
        "filter_info": "ğŸ”” Kindly add a picture first to use adjustments.",
        "blur_settings": "**ğŸ”² Smooth Adjustment Settings**",
        "blur_kernel": "Grid size",
        "blur_result": "Smooth Outcome",
        "sharpen_settings": "**âœ¨ Focus Adjustment Settings**",
        "sharpen_desc": "Boost details and outlines in the picture.",
        "sharpen_result": "Focus Outcome",
        "bg_settings": "**ğŸ¯ Backdrop Removal Settings**",
        "bg_method": "Way (demo uses HSV only now)",
        "bg_result": "Backdrop Removal Outcome",
        "gray_settings": "**âš« Monochrome Change Settings**",
        "gray_desc": "Change the picture to monochrome (black and white).",
        "gray_result": "Monochrome Outcome",
        "edge_settings": "**ğŸ” Outline Finding Settings**",
        "edge_method": "Outline way",
        "edge_result": "Outline Picture",
        "bright_settings": "**â˜€ï¸ Light & Shade Settings**",
        "bright_brightness": "Light",
        "bright_contrast": "Shade",
        "bright_result": "Light/Shade Outcome",
        "team_title": "### ğŸ‘¥ Group People",
        "team_subtitle": "Group 12 â€“ People and Jobs",
        "team_sid": "ID:",
        "team_role": "Job:",
        "upload_method_title": "### How to Upload Photo",
        "upload_method_text": "**Steps to upload a photo:**\n1. Click the **\"Add a picture here (PNG/JPG/JPEG) ğŸ“‚\"** button located at the top of the page.\n2. Select an image file from your device (supported formats: PNG, JPG, or JPEG).\n3. Wait until the image is successfully uploaded and displayed on the screen.\n4. If successful, you will see a confirmation message and a preview of the initial image.\n5. Now you can use the editing tools in the left column (geometric transformations) and right column (image adjustments).",
        "team_group": "Group:",
        "team_contribution": "Contribution:",
        "axis_x": "X-line",
        "axis_y": "Y-line",
        "axis_diag": "Cross",
        "dark_mode": "Night Style",
        "light_mode": "Day Style",
    },
    "zh": {
        "title": "ğŸ§® å›¾åƒå¤„ç†ä¸­çš„çŸ©é˜µå˜æ¢",
        "subtitle": "ğŸ¯ å®æ—¶æ¢ç´¢äºŒç»´çŸ©é˜µå˜åŒ–å’Œå›¾ç‰‡è°ƒæ•´",
        "app_goal": "ğŸ¯ **ç›®æ ‡ï¼š** é€šè¿‡çº¿æ€§ä»£æ•°ç†å¿µå±•ç¤ºäºŒç»´çŸ©é˜µå˜åŒ–å’Œå›¾ç‰‡è°ƒæ•´å¦‚ä½•å½±å“è§†è§‰æ•ˆæœçš„åŠ¨æ‰‹æ¢ç´¢ã€‚",
        "features": "- â†©ï¸ å˜åŒ–ï¼šç§»åŠ¨ã€è°ƒæ•´å¤§å°ã€æ—‹è½¬ã€å€¾æ–œã€ç¿»è½¬\n- ğŸ§½ è°ƒæ•´ï¼šå¹³æ»‘ã€èšç„¦ã€è½®å»“æ£€æµ‹ã€èƒŒæ™¯æ¸…é™¤ã€è½¬ä¸ºå•è‰²ã€è°ƒæ•´å…‰çº¿å’Œé˜´å½±",
        "concept_1_title": "### ğŸŒ€ äºŒç»´çŸ©é˜µå˜åŒ–",
        "concept_1_text1": "å¹³é¢å›¾åƒæ˜¯ä¸€ç»„ç‚¹ \\((x, y)\\)ï¼Œé€šè¿‡ç›´çº¿åŠ¨ä½œå¦‚ç§»åŠ¨ã€è°ƒæ•´å¤§å°ã€æ—‹è½¬ã€å€¾æ–œå’Œç¿»è½¬æ¥ç§»åŠ¨ï¼Œç”±2Ã—2æˆ–3Ã—3çŸ©é˜µè¡¨ç¤ºï¼ˆå‡åŒ€ç‚¹ï¼‰ã€‚",
        "concept_1_text2": "åœ¨ç‚¹ä½ç½®ä½¿ç”¨è¿™äº›çŸ©é˜µä¼šç§»åŠ¨å®ƒä»¬ï¼šè°ƒæ•´å¤§å°æ”¹å˜æ¯”ä¾‹ï¼Œæ—‹è½¬å›´ç»•ä¸­é—´æ—‹è½¬è§†å›¾ï¼Œå€¾æ–œä½¿å…¶å€¾æ–œï¼Œç¿»è½¬åœ¨é€‰å®šçº¿ä¸Šåè½¬è§†å›¾ã€‚",
        "concept_2_title": "### ğŸ“Š å›¾ç‰‡è°ƒæ•´ï¼ˆæ··åˆï¼‰",
        "concept_2_text1": "è°ƒæ•´ä½¿ç”¨ä¸€ä¸ªå°ç½‘æ ¼ï¼ˆæ··åˆçŸ©é˜µï¼‰ï¼Œåœ¨å›¾åƒä¸Šæ»‘åŠ¨ï¼›åœ¨æ¯ä¸ªç‚¹ï¼Œå®ƒé€šè¿‡æ·»åŠ ç½‘æ ¼ä¹˜ä»¥é™„è¿‘ç‚¹æ¥åˆ¶ä½œæ–°çš„ç‚¹å€¼ã€‚",
        "concept_2_text2": "å…·æœ‰å‡åŒ€å¥½æ•°å­—çš„ç½‘æ ¼ä½¿è§†å›¾æ›´æŸ”å’Œæˆ–æ¨¡ç³Šï¼Œè€Œå…·æœ‰å¤§å¥½ä¸­é—´å’Œåä¾§é¢çš„ç½‘æ ¼ä½¿å…¶æ›´é”åˆ©å¹¶çªå‡ºè¾¹ç¼˜ã€‚",
        "concept_3_title": "### ğŸ² ä¸ºä»€ä¹ˆåŠ¨æ‰‹ï¼Ÿ",
        "concept_3_text1": "è¯¥åº”ç”¨æ˜¯åŠ¨æ‰‹å¼çš„ï¼Œå› ä¸ºç”¨æˆ·å¯ä»¥è°ƒæ•´è®¾ç½®ï¼ˆå¦‚è½¬åŠ¨åº¦æ•°ã€å¤§å°ç‡ã€å€¾æ–œå¼ºåº¦ã€ç”¨äºå¹³æ»‘æˆ–èšç„¦çš„ç½‘æ ¼ç§ç±»ç­‰ï¼‰ï¼Œå¹¶ç«‹å³åœ¨è§†å›¾ä¸Šçœ‹åˆ°å˜åŒ–ã€‚âœ¨",
        "concept_3_text2": "å®ƒå°†ç½‘æ ¼æˆ–çŸ©é˜µè®¾ç½®é“¾æ¥åˆ°å¯è§æ•ˆæœï¼Œä½¿ç›´çº¿å˜åŒ–å’Œæ··åˆç­‰æ€æƒ³æ›´å®¹æ˜“è‡ªç„¶ç†è§£ã€‚",
        "quick_concepts": "#### ğŸ“ å…³é”®ç†å¿µ",
        "quick_concepts_text": "- â†©ï¸ äºŒç»´å˜åŒ–ï¼šç§»åŠ¨ç‚¹ä½ç½®ï¼ˆç§»åŠ¨ã€è°ƒæ•´å¤§å°ã€æ—‹è½¬ã€å€¾æ–œã€ç¿»è½¬ï¼‰ã€‚\n- ğŸ“Š æ··åˆï¼šä¸€ä¸ªå°ç½‘æ ¼åœ¨å›¾åƒä¸Šæ»‘åŠ¨ä»¥åˆ¶ä½œæ–°çš„ç‚¹å€¼ã€‚",
        "upload_title": "### ğŸ“· æ·»åŠ å›¾ç‰‡",
        "upload_label": "åœ¨æ­¤å¤„æ·»åŠ å›¾ç‰‡ï¼ˆPNG/JPG/JPEGï¼‰ğŸ“‚",
        "upload_success": "âœ… å›¾ç‰‡æ·»åŠ æˆåŠŸï¼",
        "upload_preview": "ğŸ“· èµ·å§‹å›¾ç‰‡è§†å›¾",
        "upload_info": "â¬†ï¸ è¯·å…ˆæ·»åŠ å›¾ç‰‡ä»¥ä½¿ç”¨ä¸‹é¢çš„å·¥å…·ã€‚",
        "tools_title": "### ğŸ”§ å›¾ç‰‡ç¼–è¾‘å·¥å…·",
        "tools_subtitle": "ğŸ›ï¸ é€‰æ‹©ä¸‹é¢çš„æ¡†ä»¥æ‰“å¼€å˜åŒ–æˆ–è°ƒæ•´è®¾ç½®ã€‚",
        "geo_title": "#### ğŸ”„ å½¢çŠ¶å˜åŒ–",
        "geo_desc": "å½¢çŠ¶å˜åŒ–ä½¿ç”¨ç›´çº¿åŠ¨ä½œï¼ˆçŸ©é˜µï¼‰æ”¹å˜ç‚¹ä½ç½®ã€å¤§å°å’Œæ–¹å‘ã€‚",
        "btn_translation": "â†”ï¸ ç§»åŠ¨",
        "btn_scaling": "ğŸ“ å¤§å°",
        "btn_rotation": "ğŸ”„ æ—‹è½¬",
        "btn_shearing": "ğŸ“ å€¾æ–œ",
        "btn_reflection": "ğŸª é•œåƒ",
        "geo_info": "ğŸ”” è¯·å…ˆæ·»åŠ å›¾ç‰‡ä»¥å°è¯•å˜åŒ–ã€‚",
        "trans_settings": "**â†”ï¸ ç§»åŠ¨è®¾ç½®**",
        "trans_dx": "dxï¼ˆä¾§é¢ç§»åŠ¨ï¼‰",
        "trans_dy": "dyï¼ˆä¸Šä¸‹ç§»åŠ¨ï¼‰",
        "btn_apply": "ä½¿ç”¨",
        "trans_result": "ç§»åŠ¨ç»“æœ",
        "scale_settings": "**ğŸ“ å¤§å°è®¾ç½®**",
        "scale_x": "å¤§å° X",
        "scale_y": "å¤§å° Y",
        "scale_result": "å¤§å°ç»“æœ",
        "rot_settings": "**ğŸ”„ æ—‹è½¬è®¾ç½®**",
        "rot_angle": "æ—‹è½¬è§’åº¦ï¼ˆåº¦ï¼‰",
        "rot_result": "æ—‹è½¬ç»“æœ",
        "shear_settings": "**ğŸ“ å€¾æ–œè®¾ç½®**",
        "shear_x": "å€¾æ–œå› å­ X",
        "shear_y": "å€¾æ–œå› å­ Y",
        "shear_result": "å€¾æ–œç»“æœ",
        "refl_settings": "**ğŸª é•œåƒè®¾ç½®**",
        "refl_axis": "é•œåƒçº¿",
        "refl_result": "é•œåƒç»“æœ",
        "hist_title": "#### ğŸ“ˆ å›¾ç‰‡å›¾è¡¨",
        "hist_desc": "å›¾è¡¨æ˜¾ç¤ºç‚¹å¼ºåº¦çš„åˆ†å¸ƒï¼ˆæš—â€“äº®ï¼‰ï¼Œæœ‰åŠ©äºæ£€æŸ¥å…‰çº¿å’Œé˜´å½±ã€‚",
        "btn_histogram": "æ˜¾ç¤ºå›¾è¡¨ ğŸ“ˆ",
        "hist_warning": "è¯·å…ˆæ·»åŠ å›¾ç‰‡ä»¥æ˜¾ç¤ºå›¾è¡¨ã€‚",
        "filter_title": "#### ğŸ”§ å›¾ç‰‡è°ƒæ•´",
        "filter_desc": "è°ƒæ•´åŸºäºé‚»å±…ï¼ˆæ··åˆï¼‰æ”¹å˜ç‚¹å€¼ä»¥è¿›è¡Œå¹³æ»‘ã€èšç„¦ã€è½®å»“æŸ¥æ‰¾ã€èƒŒæ™¯ç§»é™¤ç­‰ã€‚",
        "btn_blur": "ğŸ”² å¹³æ»‘",
        "btn_sharpen": "âœ¨ èšç„¦",
        "btn_background": "ğŸ¯ èƒŒæ™¯",
        "btn_grayscale": "âš« å•è‰²",
        "btn_edge": "ğŸ” è½®å»“",
        "btn_brightness": "â˜€ï¸ å…‰çº¿",
        "filter_info": "ğŸ”” è¯·å…ˆæ·»åŠ å›¾ç‰‡ä»¥ä½¿ç”¨è°ƒæ•´ã€‚",
        "blur_settings": "**ğŸ”² å¹³æ»‘è°ƒæ•´è®¾ç½®**",
        "blur_kernel": "ç½‘æ ¼å¤§å°",
        "blur_result": "å¹³æ»‘ç»“æœ",
        "sharpen_settings": "**âœ¨ èšç„¦è°ƒæ•´è®¾ç½®**",
        "sharpen_desc": "æå‡å›¾ç‰‡ä¸­çš„ç»†èŠ‚å’Œè½®å»“ã€‚",
        "sharpen_result": "èšç„¦ç»“æœ",
        "bg_settings": "**ğŸ¯ èƒŒæ™¯ç§»é™¤è®¾ç½®**",
        "bg_method": "æ–¹å¼ï¼ˆæ¼”ç¤ºç›®å‰ä»…ä½¿ç”¨HSVï¼‰",
        "bg_result": "èƒŒæ™¯ç§»é™¤ç»“æœ",
        "gray_settings": "**âš« å•è‰²å˜åŒ–è®¾ç½®**",
        "gray_desc": "å°†å›¾ç‰‡è½¬ä¸ºå•è‰²ï¼ˆé»‘ç™½ï¼‰ã€‚",
        "gray_result": "å•è‰²ç»“æœ",
        "edge_settings": "**ğŸ” è½®å»“æŸ¥æ‰¾è®¾ç½®**",
        "edge_method": "è½®å»“æ–¹å¼",
        "edge_result": "è½®å»“å›¾ç‰‡",
        "bright_settings": "**â˜€ï¸ å…‰çº¿å’Œé˜´å½±è®¾ç½®**",
        "bright_brightness": "å…‰çº¿",
        "bright_contrast": "é˜´å½±",
        "bright_result": "å…‰çº¿/é˜´å½±ç»“æœ",
        "team_title": "### ğŸ‘¥ ç»„å‘˜",
        "team_subtitle": "ç¬¬12ç»„ â€“ äººå‘˜å’ŒèŒåŠ¡",
        "team_sid": "ID:",
        "team_role": "èŒåŠ¡:",
        "team_group": "ç»„:",
        "team_contribution": "å¸®åŠ©ï¼š",
        "upload_method_title": "### å¦‚ä½•ä¸Šä¼ ç…§ç‰‡",
        "upload_method_text": "**ä¸Šä¼ ç…§ç‰‡çš„æ­¥éª¤ï¼š**\n1. ç‚¹å‡»ä½äºé¡µé¢é¡¶éƒ¨çš„ **\"åœ¨æ­¤å¤„æ·»åŠ å›¾ç‰‡ï¼ˆPNG/JPG/JPEGï¼‰ğŸ“‚\"** æŒ‰é’®ã€‚\n2. ä»æ‚¨çš„è®¾å¤‡ä¸­é€‰æ‹©å›¾åƒæ–‡ä»¶ï¼ˆæ”¯æŒçš„æ ¼å¼ï¼šPNGã€JPG æˆ– JPEGï¼‰ã€‚\n3. ç­‰å¾…å›¾åƒæˆåŠŸä¸Šä¼ å¹¶æ˜¾ç¤ºåœ¨å±å¹•ä¸Šã€‚\n4. å¦‚æœæˆåŠŸï¼Œæ‚¨å°†çœ‹åˆ°ç¡®è®¤æ¶ˆæ¯å’Œåˆå§‹å›¾åƒçš„é¢„è§ˆã€‚\n5. ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨å·¦ä¾§åˆ—ï¼ˆå‡ ä½•å˜æ¢ï¼‰å’Œå³ä¾§åˆ—ï¼ˆå›¾åƒè°ƒæ•´ï¼‰ä¸­çš„ç¼–è¾‘å·¥å…·ã€‚",
        "axis_x": "Xçº¿",
        "axis_y": "Yçº¿",
        "axis_diag": "äº¤å‰",
        "dark_mode": "å¤œé—´é£æ ¼",
        "light_mode": "ç™½å¤©é£æ ¼",
    }
}

# ===================== HEADER =====================

lang = st.session_state["language"]
t = translations[lang]

with st.container(border=True):
    header_col1, header_col2 = st.columns([6, 4], vertical_alignment="center")
    with header_col1:
        st.title(t["title"])
    with header_col2:
        lang_col1, lang_col2, lang_col3 = st.columns(3)
        with lang_col1:
            if st.button("ğŸ‡®ğŸ‡© ID", key="lang_id", use_container_width=True):
                st.session_state["language"] = "id"
                st.rerun()
        with lang_col2:
            if st.button("ğŸ‡¬ğŸ‡§ EN", key="lang_en", use_container_width=True):
                st.session_state["language"] = "en"
                st.rerun()
        with lang_col3:
            if st.button("ğŸ‡¨ğŸ‡³ CN", key="lang_cn", use_container_width=True):
                st.session_state["language"] = "zh"
                st.rerun()

st.subheader(t["subtitle"])

# ----- Global layout + theme CSS (light only) -----
base_css = """
<style>
.block-container {
    max-width: 1200px;
    padding: 2.5rem 2rem 1.2rem 2rem;
}
section[data-testid="stExpander"]{
    border-radius:10px;
    padding:8px;
    box-shadow:0 1px 6px rgba(0,0,0,0.04);
    margin-bottom:10px;
    background-color: var(--stLightBlue-50);
}
section[data-testid="stExpander"] .streamlit-expanderHeader{
    font-size:16px;
}
.stImage > img{
    max-height:420px;
    object-fit:contain;
}
div[data-testid="column"] button {
    padding-top: 8px !important;
    padding-bottom: 8px !important;
    padding-left: 12px !important;
    padding-right: 12px !important;
    font-size: 14px !important;
    width: 100%;
    font-weight: 500 !important;
}
/* Green border for containers */
div[data-testid="stVerticalBlock"] > div[data-testid="stVerticalBlock"] > div[data-testid="stVerticalBlockBorderWrapper"] {
    border: 2px solid #4CAF50 !important;
    border-radius: 12px !important;
}
/* Team member photo container - square with crop */
.team-photo-container {
    width: 140px;
    height: 140px;
    border-radius: 50%;
    overflow: hidden;
    margin: 0 auto;
    display: flex;
    align-items: center;
    justify-content: center;
    background: #f0f0f0;
    border: 3px solid #4CAF50;
}
.team-photo-container img {
    width: 100%;
    height: 100%;
    object-fit: cover;
    object-position: center;
}
</style>
"""
light_css = """
<style>
.stMarkdown, .stMarkdown p, .stMarkdown li {
    color: #1b5e20 !important;
}
button[kind="secondary"] {
    background-color: #ffffff !important;
    color: #1b5e20 !important;
    border: 2px solid #4CAF50 !important;
    font-weight: 600 !important;
}
button[kind="secondary"]:hover {
    background-color: #e8f5e9 !important;
    border-color: #2e7d32 !important;
}
.team-photo-container {
    background: #e8f5e9;
    border-color: #4CAF50;
}
</style>
"""
st.markdown(base_css, unsafe_allow_html=True)
st.markdown(light_css, unsafe_allow_html=True)  # hanya light mode [file:2]

# ===================== APP GOAL AND CONCEPTS =====================

with st.container(border=True):
    st.markdown(t["app_goal"])
    st.markdown(t["features"])

with st.container(border=True):
    st.markdown(t["quick_concepts"])
    st.markdown(t["quick_concepts_text"])

with st.container(border=True):
    st.markdown(t["concept_1_title"])
    st.markdown(t["concept_1_text1"])
    st.markdown(t["concept_1_text2"])

with st.container(border=True):
    st.markdown(t["concept_2_title"])
    st.markdown(t["concept_2_text1"])
    st.markdown(t["concept_2_text2"])

with st.container(border=True):
    st.markdown(t["concept_3_title"])
    st.markdown(t["concept_3_text1"])
    st.markdown(t["concept_3_text2"])

# ===================== HELPER FUNCTIONS =====================

def load_image(file):
    img = Image.open(file).convert("RGB")
    img_np = np.array(img)
    return img_np

def to_opencv(img_rgb):
    return cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

def to_streamlit(img_bgr):
    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

def apply_affine_transform(img_rgb, M, output_size=None):
    img_bgr = to_opencv(img_rgb)
    h, w = img_bgr.shape[:2]
    if output_size is None:
        output_size = (w, h)
    if M.shape == (3, 3):
        M_affine = M[0:2, :]
    else:
        M_affine = M
    transformed = cv2.warpAffine(
        img_bgr, M_affine, output_size,
        flags=cv2.INTER_LINEAR,
        borderMode=cv2.BORDER_REFLECT
    )
    return to_streamlit(transformed)

def manual_convolution_gray(img_gray, kernel):
    k_h, k_w = kernel.shape
    pad_h = k_h // 2
    pad_w = k_w // 2
    padded = np.pad(img_gray, ((pad_h, pad_h), (pad_w, pad_w)), mode="reflect")
    h, w = img_gray.shape
    output = np.zeros_like(img_gray, dtype=np.float32)
    for i in range(h):
        for j in range(w):
            region = padded[i:i + k_h, j:j + k_w]
            output[i, j] = np.sum(region * kernel)
    output = np.clip(output, 0, 255).astype(np.uint8)
    return output

def rgb_to_gray(img_rgb):
    img_bgr = to_opencv(img_rgb)
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    return gray

def adjust_brightness_contrast(img_rgb, brightness=0, contrast=0):
    img_bgr = to_opencv(img_rgb)
    beta = brightness
    alpha = 1 + (contrast / 100.0)
    adjusted = cv2.convertScaleAbs(img_bgr, alpha=alpha, beta=beta)
    return to_streamlit(adjusted)

def image_to_bytes(img_rgb, fmt="PNG"):
    if img_rgb is None:
        raise ValueError("image_to_bytes received None image")
    arr = np.array(img_rgb)
    if arr.ndim == 2:
        arr = cv2.cvtColor(arr, cv2.COLOR_GRAY2RGB)
    if fmt.upper() == "JPEG" and arr.ndim == 3 and arr.shape[2] == 4:
        arr = arr[:, :, :3]
    pil_img = Image.fromarray(arr.astype("uint8"))
    buf = BytesIO()
    pil_img.save(buf, format=fmt)
    return buf.getvalue()

# ===================== ADVANCED BACKGROUND HELPERS =====================

def _feather_mask(mask: np.ndarray, radius: int) -> np.ndarray:
    """Feather/smooth mask edges using Gaussian blur."""
    if radius <= 0:
        m = mask.astype(np.float32)
        if m.max() > 1.0:
            m = m / 255.0
        return m

    m = mask.astype(np.float32)
    if m.max() > 1.0:
        m = m / 255.0

    ksize = radius * 2 + 1
    m_blur = cv2.GaussianBlur(m, (ksize, ksize), 0)
    return np.clip(m_blur, 0.0, 1.0)


def _refine_hair_region(image_rgb: np.ndarray,
                        mask: np.ndarray,
                        refine_hair: bool = True) -> np.ndarray:
    """Refine mask around hair and fine details using edge cues."""
    m = mask.copy().astype(np.uint8)
    if m.max() > 1:
        m = (m > 127).astype(np.uint8)

    if not refine_hair:
        return m

    img_bgr = to_opencv(image_rgb)
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    edge_dilated = cv2.dilate(edges, np.ones((3, 3), np.uint8))

    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))
    m = cv2.morphologyEx(m, cv2.MORPH_OPEN, np.ones((2, 2), np.uint8))

    m[edge_dilated > 0] = 1
    return m.astype(np.uint8)


def _remove_small_holes(mask: np.ndarray,
                        min_area: int = 100) -> np.ndarray:
    """Remove small holes inside the foreground mask."""
    m = mask.copy().astype(np.uint8)
    if m.max() > 1:
        m = (m > 127).astype(np.uint8)

    inv = (1 - m).astype(np.uint8)
    contours, _ = cv2.findContours(inv, cv2.RETR_EXTERNAL,
                                   cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours:
        if cv2.contourArea(cnt) < min_area:
            cv2.drawContours(inv, [cnt], -1, 0, thickness=cv2.FILLED)

    cleaned = 1 - inv
    return cleaned.astype(np.uint8)


def _apply_solid_background(image_rgb: np.ndarray,
                            mask_float: np.ndarray,
                            color: tuple[int, int, int]) -> np.ndarray:
    """Replace background with solid RGB color."""
    h, w = image_rgb.shape[:2]
    bg = np.full((h, w, 3), color, dtype=np.uint8)

    alpha = mask_float[:, :, None]
    out = (alpha * image_rgb.astype(np.float32) +
           (1.0 - alpha) * bg.astype(np.float32))
    return out.astype(np.uint8)


def _apply_blur_background(image_rgb: np.ndarray,
                           mask_float: np.ndarray,
                           ksize: int = 21) -> np.ndarray:
    """Blur only the background while keeping subject sharp."""
    if ksize % 2 == 0:
        ksize += 1
    blurred = cv2.GaussianBlur(image_rgb, (ksize, ksize), 0)

    alpha = mask_float[:, :, None]
    out = (alpha * image_rgb.astype(np.float32) +
           (1.0 - alpha) * blurred.astype(np.float32))
    return out.astype(np.uint8)


def segment_foreground(image: np.ndarray) -> np.ndarray:
    """
    SIMPLE foreground segmentation.

    Untuk sementara: subject dianggap di tengah gambar (ellipse).
    Nanti bisa kamu ganti dengan model segmentasi beneran.
    """
    h, w = image.shape[:2]
    mask = np.zeros((h, w), dtype=np.uint8)

    center = (w // 2, h // 2)
    axes = (int(w * 0.35), int(h * 0.45))
    cv2.ellipse(mask, center, axes, 0, 0, 360, 255, -1)

    return mask


# ===================== ADVANCED BACKGROUND MAIN FUNCTION =====================

def remove_background_advanced(
    image: np.ndarray,
    mode: str = "auto",
    target_background_type: str | None = None,
    output_mode: str = "transparent",
    solid_color: tuple[int, int, int] | None = None,
    feather_radius: int = 3,
    refine_hair: bool = True,
) -> np.ndarray:
    """
    Advanced background removal supporting multiple background types and outputs.
    """
    if image is None:
        raise ValueError("Input image is None")

    if image.ndim != 3 or image.shape[2] != 3:
        raise ValueError("`image` must be RGB with shape (H, W, 3)")

    h, w = image.shape[:2]
    img_bgr = to_opencv(image)
    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    img_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    L_channel = img_lab[:, :, 0]

    bg_type = (target_background_type or mode or "auto").lower()

    # ---------- RAW MASK PER MODE ----------
    if bg_type in ["solid", "studio"]:
        border_thick = max(5, min(h, w) // 20)
        border_pixels = np.concatenate([
            img_hsv[:border_thick, :, :].reshape(-1, 3),
            img_hsv[-border_thick:, :, :].reshape(-1, 3),
            img_hsv[:, :border_thick, :].reshape(-1, 3),
            img_hsv[:, -border_thick:, :].reshape(-1, 3),
        ], axis=0)
        bg_color = np.median(border_pixels, axis=0).astype(np.float32)

        hsv_flat = img_hsv.reshape(-1, 3).astype(np.float32)
        dist = np.linalg.norm(hsv_flat - bg_color[None, :], axis=1)
        dist_img = dist.reshape(h, w)
        thresh = np.percentile(dist_img, 60)
        raw_mask = (dist_img > thresh).astype(np.uint8)

    elif bg_type == "gradient":
        L_norm = cv2.normalize(L_channel, None, 0, 255, cv2.NORM_MINMAX)
        edges = cv2.Canny(L_norm, 50, 150)
        thr = cv2.adaptiveThreshold(
            L_norm, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 21, 5
        )
        raw_mask = ((thr == 255) | (edges > 0)).astype(np.uint8)

    elif bg_type == "textured":
        prior_mask = segment_foreground(image)
        if prior_mask.max() > 1:
            prior_mask = (prior_mask > 127).astype(np.uint8)

        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 80, 160)
        prior_dilated = cv2.dilate(prior_mask, np.ones((7, 7), np.uint8))
        edge_near_prior = cv2.dilate(edges, np.ones((5, 5), np.uint8))
        raw_mask = ((prior_dilated == 1) | (edge_near_prior > 0)).astype(np.uint8)

    elif bg_type == "natural":
        prior_mask = segment_foreground(image)
        if prior_mask.max() > 1:
            prior_mask = (prior_mask > 127).astype(np.uint8)

        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 80, 200)

        border_thick = max(5, min(h, w) // 20)
        border_pixels = img_lab[:border_thick, :, :].reshape(-1, 3)
        bg_L = np.median(border_pixels[:, 0])

        L_diff = np.abs(L_channel.astype(np.float32) - bg_L)
        contrast_mask = (L_diff > 15).astype(np.uint8)

        raw_mask = ((prior_mask == 1) | (edges > 0)) & contrast_mask

    elif bg_type == "minimalist":
        border_thick = max(5, min(h, w) // 20)
        border_pixels = img_hsv[:border_thick, :, :].reshape(-1, 3)
        bg_color = np.median(border_pixels, axis=0).astype(np.float32)

        hsv_flat = img_hsv.reshape(-1, 3).astype(np.float32)
        dist = np.linalg.norm(hsv_flat - bg_color[None, :], axis=1)
        dist_img = dist.reshape(h, w)
        thresh = np.percentile(dist_img, 70)
        raw_mask = (dist_img > thresh).astype(np.uint8)

    elif bg_type == "abstract":
        prior_mask = segment_foreground(image)
        if prior_mask.max() > 1:
            prior_mask = (prior_mask > 127).astype(np.uint8)

        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)

        raw = ((prior_mask == 1) | (edges > 0)).astype(np.uint8)
        raw = cv2.morphologyEx(raw, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))
        raw_mask = raw

    elif bg_type == "vintage":
        L_blur = cv2.GaussianBlur(L_channel, (5, 5), 0)
        _, thr = cv2.threshold(L_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        raw = thr == 255
        raw = cv2.morphologyEx(raw.astype(np.uint8), cv2.MORPH_OPEN,
                               np.ones((3, 3), np.uint8))
        raw_mask = raw

    else:
        # AUTO: analisa rata/tidaknya brightness di border
        border_thick = max(5, min(h, w) // 20)
        border_pixels = img_lab[:border_thick, :, :].reshape(-1, 3)
        L_border = border_pixels[:, 0]
        std_L = np.std(L_border)

        if std_L < 5:
            return remove_background_advanced(
                image=image,
                mode="solid",
                target_background_type="solid",
                output_mode=output_mode,
                solid_color=solid_color,
                feather_radius=feather_radius,
                refine_hair=refine_hair,
            )
        elif std_L < 15:
            return remove_background_advanced(
                image=image,
                mode="gradient",
                target_background_type="gradient",
                output_mode=output_mode,
                solid_color=solid_color,
                feather_radius=feather_radius,
                refine_hair=refine_hair,
            )
        else:
            return remove_background_advanced(
                image=image,
                mode="textured",
                target_background_type="textured",
                output_mode=output_mode,
                solid_color=solid_color,
                feather_radius=feather_radius,
                refine_hair=refine_hair,
            )

    # ---------- POST-PROCESSING MASK ----------
    mask_clean = _remove_small_holes(raw_mask, min_area=100)
    mask_refined_bin = _refine_hair_region(image, mask_clean, refine_hair=refine_hair)
    mask_float = _feather_mask(mask_refined_bin, radius=feather_radius)

    # ---------- OUTPUT ----------
    if output_mode == "custom_mask":
        return (mask_float * 255.0).astype(np.uint8)

    if output_mode == "transparent":
        alpha = (mask_float * 255.0).astype(np.uint8)
        rgba = np.dstack([image.astype(np.uint8), alpha])
        return rgba

    if output_mode == "solid_color":
        if solid_color is None:
            solid_color = (255, 255, 255)
        rgb_out = _apply_solid_background(image.astype(np.uint8),
                                          mask_float, solid_color)
        return rgb_out

    if output_mode == "blurred":
        rgb_out = _apply_blur_background(image.astype(np.uint8),
                                         mask_float, ksize=25)
        return rgb_out

    raise ValueError(f"Unsupported output_mode: {output_mode}")

def compute_histogram(img_rgb):
    img_bgr = to_opencv(img_rgb)
    color = ('b', 'g', 'r')
    fig, ax = plt.subplots(figsize=(8, 4))
    for i, col in enumerate(color):
        hist = cv2.calcHist([img_bgr], [i], None, [256], [0, 256])
        ax.plot(hist, color=col)
        ax.set_xlim([0, 256])
    ax.set_title("Color Histogram")
    ax.set_xlabel("Pixel value")
    ax.set_ylabel("Frequency")
    fig.tight_layout()
    return fig

def simple_background_removal_hsv(img_rgb):
    img_bgr = to_opencv(img_rgb)
    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    lower = np.array([0, 0, 0])
    upper = np.array([180, 255, 200])
    mask_bg = cv2.inRange(hsv, lower, upper)
    mask_fg = cv2.bitwise_not(mask_bg)
    fg = cv2.bitwise_and(img_bgr, img_bgr, mask=mask_fg)
    fg_rgb = to_streamlit(fg)
    return fg_rgb

def image_to_bytes(img_rgb, fmt="PNG"):
    """
    Convert numpy RGB or RGBA image to bytes for download.
    - PNG: akan simpan apa adanya (termasuk alpha/transparan).
    - JPEG: otomatis buang alpha (RGBA -> RGB) agar tidak error.
    """
    if img_rgb is None:
        raise ValueError("image_to_bytes received None image")

    arr = np.array(img_rgb)
    # kalau grayscale, naikkan ke RGB
    if arr.ndim == 2:
        arr = cv2.cvtColor(arr, cv2.COLOR_GRAY2RGB)

    # kalau JPEG, buang alpha dulu kalau ada
    if fmt.upper() == "JPEG" and arr.ndim == 3 and arr.shape[2] == 4:
        arr = arr[:, :, :3]

    pil_img = Image.fromarray(arr.astype("uint8"))
    buf = BytesIO()
    pil_img.save(buf, format=fmt)
    return buf.getvalue()

def create_square_image_html(image_path, size=140):
    """Create HTML for square cropped image"""
    return f"""
    <div class="team-photo-container">
        <img src="data:image/jpeg;base64,{{base64_img}}" alt="Team member"/>
    </div>
    """

# ===================== TEAM PHOTO HELPERS =====================

def safe_display_square_image(path):
    if os.path.exists(path):
        try:
            img = Image.open(path)
            if img.mode != "RGB":
                img = img.convert("RGB")
            width, height = img.size
            min_dim = min(width, height)
            left = (width - min_dim) // 2
            top = (height - min_dim) // 2
            right = left + min_dim
            bottom = top + min_dim
            img_cropped = img.crop((left, top, right, bottom))
            img_resized = img_cropped.resize((140, 140), Image.Resampling.LANCZOS)

            buffered = BytesIO()
            img_resized.save(buffered, format="JPEG")
            img_str = base64.b64encode(buffered.getvalue()).decode()

            st.markdown(
                f"""
                <div class="team-photo-container">
                    <img src="data:image/jpeg;base64,{img_str}" alt="Team member"/>
                </div>
                """,
                unsafe_allow_html=True,
            )
        except Exception as e:
            st.error(f"Error loading image: {e}")
    else:
        st.markdown(
            """
            <div class="team-photo-container">
                <div style="width:100%; height:100%; display:flex; align-items:center; justify-content:center; background:#ddd; color:#666;">
                    No Image
                </div>
            </div>
            """,
            unsafe_allow_html=True,
        )

# Ensure images folder and placeholders exist
images_dir = "images"
os.makedirs(images_dir, exist_ok=True)
placeholder_files = [
    os.path.join(images_dir, "gitsi.jpeg"),
    os.path.join(images_dir, "bella.jpeg"),
    os.path.join(images_dir, "chinta.jpeg"),
    os.path.join(images_dir, "yessa.jpeg"),
]
for p in placeholder_files:
    if not os.path.exists(p):
        placeholder = Image.new("RGB", (400, 400), color=(200, 200, 200))
        placeholder.save(p, format="JPEG")

# ===================== UPLOAD IMAGE =====================

with st.container(border=True):
    st.markdown(t["upload_title"])
    uploaded_file = st.file_uploader(
        label=t["upload_label"],
        type=["png", "jpg", "jpeg"],
        key="image_uploader",
    )
    if uploaded_file is not None:
        original_img = load_image(uploaded_file)
        st.session_state.original_img = original_img
        st.success(t["upload_success"])
        st.image(original_img, caption=t["upload_preview"], use_column_width=True)
    else:
        st.info(t["upload_info"])

original_img = st.session_state.original_img

with st.container(border=True):
    st.markdown(t["upload_method_title"])
    st.markdown(t["upload_method_text"])

# ===================== TOOLS TITLE =====================

st.markdown(t["tools_title"])
st.write(t["tools_subtitle"])

tools_col_left, tools_col_right = st.columns(2, vertical_alignment="top")  # PENTING [file:2]

# ==================== LEFT: GEOMETRIC TRANSFORMATIONS ====================

with tools_col_left:
    # Box 1: judul + tombol
    with st.container(border=True):
        st.markdown(t["geo_title"])
        st.write(t["geo_desc"])
        st.markdown("---")

        trans_col1, trans_col2, trans_col3 = st.columns(3)
        with trans_col1:
            if st.button(t["btn_translation"], key="btn_trans_click", type="secondary"):
                st.session_state["geo_transform"] = "translation"
        with trans_col2:
            if st.button(t["btn_scaling"], key="btn_scale_click", type="secondary"):
                st.session_state["geo_transform"] = "scaling"
        with trans_col3:
            if st.button(t["btn_rotation"], key="btn_rot_click", type="secondary"):
                st.session_state["geo_transform"] = "rotation"

        trans_col4, trans_col5, _ = st.columns(3)
        with trans_col4:
            if st.button(t["btn_shearing"], key="btn_shear_click", type="secondary"):
                st.session_state["geo_transform"] = "shearing"
        with trans_col5:
            if st.button(t["btn_reflection"], key="btn_refl_click", type="secondary"):
                st.session_state["geo_transform"] = "reflection"

    # Box 2: panel parameter (dipindah ke bawah)
    with st.container(border=True):
        if original_img is None:
            st.info(t["geo_info"])
        else:
            if st.session_state["geo_transform"] == "translation":
                st.markdown(t["trans_settings"])
                dx = st.slider(t["trans_dx"], -200, 200, 0, key="trans_dx")
                dy = st.slider(t["trans_dy"], -200, 200, 0, key="trans_dy")
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_trans", type="primary"):
                    T = np.array([[1, 0, dx],
                                  [0, 1, dy],
                                  [0, 0, 1]], dtype=np.float32)
                    translated_img = apply_affine_transform(original_img, T)
                    st.image(translated_img, caption=t["trans_result"], use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(translated_img, fmt="PNG"),
                            file_name="translation_result.png",
                            mime="image/png",
                            key="dl_trans_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(translated_img, fmt="JPEG"),
                            file_name="translation_result.jpg",
                            mime="image/jpeg",
                            key="dl_trans_jpg",
                        )

            elif st.session_state["geo_transform"] == "scaling":
                st.markdown(t["scale_settings"])
                sx = st.slider(t["scale_x"], 0.1, 3.0, 1.0, key="scale_x")
                sy = st.slider(t["scale_y"], 0.1, 3.0, 1.0, key="scale_y")
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_scale", type="primary"):
                    h, w = original_img.shape[:2]
                    S = np.array([[sx, 0, 0],
                                  [0, sy, 0],
                                  [0, 0, 1]], dtype=np.float32)
                    new_w = int(w * sx)
                    new_h = int(h * sy)
                    scaled_img = apply_affine_transform(original_img, S, output_size=(new_w, new_h))
                    st.image(scaled_img, caption=t["scale_result"], use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(scaled_img, fmt="PNG"),
                            file_name="scaling_result.png",
                            mime="image/png",
                            key="dl_scale_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(scaled_img, fmt="JPEG"),
                            file_name="scaling_result.jpg",
                            mime="image/jpeg",
                            key="dl_scale_jpg",
                        )

            elif st.session_state["geo_transform"] == "rotation":
                st.markdown(t["rot_settings"])
                angle = st.slider(t["rot_angle"], -180, 180, 0, key="rot_angle")
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_rot", type="primary"):
                    h, w = original_img.shape[:2]
                    cx, cy = w / 2, h / 2
                    theta = np.deg2rad(angle)
                    cos_t = np.cos(theta)
                    sin_t = np.sin(theta)
                    R = np.array([[cos_t, -sin_t, 0],
                                  [sin_t,  cos_t, 0],
                                  [0,      0,     1]], dtype=np.float32)
                    T1 = np.array([[1, 0, -cx],
                                   [0, 1, -cy],
                                   [0, 0, 1]], dtype=np.float32)
                    T2 = np.array([[1, 0, cx],
                                   [0, 1, cy],
                                   [0, 0, 1]], dtype=np.float32)
                    M = T2 @ R @ T1
                    rotated_img = apply_affine_transform(original_img, M)
                    st.image(rotated_img, caption=t["rot_result"], use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(rotated_img, fmt="PNG"),
                            file_name="rotation_result.png",
                            mime="image/png",
                            key="dl_rot_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(rotated_img, fmt="JPEG"),
                            file_name="rotation_result.jpg",
                            mime="image/jpeg",
                            key="dl_rot_jpg",
                        )

            elif st.session_state["geo_transform"] == "shearing":
                st.markdown(t["shear_settings"])
                shear_x = st.slider(t["shear_x"], -1.0, 1.0, 0.0, key="shear_x")
                shear_y = st.slider(t["shear_y"], -1.0, 1.0, 0.0, key="shear_y")
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_shear", type="primary"):
                    Sh = np.array([[1,      shear_x, 0],
                                   [shear_y, 1,      0],
                                   [0,       0,      1]], dtype=np.float32)
                    sheared_img = apply_affine_transform(original_img, Sh)
                    st.image(sheared_img, caption=t["shear_result"], use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(sheared_img, fmt="PNG"),
                            file_name="shearing_result.png",
                            mime="image/png",
                            key="dl_shear_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(sheared_img, fmt="JPEG"),
                            file_name="shearing_result.jpg",
                            mime="image/jpeg",
                            key="dl_shear_jpg",
                        )

            elif st.session_state["geo_transform"] == "reflection":
                st.markdown(t["refl_settings"])
                axis = st.selectbox(
                    t["refl_axis"],
                    [t["axis_x"], t["axis_y"], t["axis_diag"]],
                    key="refl_axis",
                )
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_refl", type="primary"):
                    h, w = original_img.shape[:2]
                    if axis == t["axis_x"]:
                        Rf = np.array([[1, 0, 0],
                                       [0, -1, h],
                                       [0, 0, 1]], dtype=np.float32)
                    elif axis == t["axis_y"]:
                        Rf = np.array([[-1, 0, w],
                                       [0, 1, 0],
                                       [0, 0, 1]], dtype=np.float32)
                    else:
                        Rf = np.array([[0, 1, 0],
                                       [1, 0, 0],
                                       [0, 0, 1]], dtype=np.float32)
                    reflected_img = apply_affine_transform(original_img, Rf)
                    st.image(reflected_img, caption=t["refl_result"], use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(reflected_img, fmt="PNG"),
                            file_name="reflection_result.png",
                            mime="image/png",
                            key="dl_refl_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(reflected_img, fmt="JPEG"),
                            file_name="reflection_result.jpg",
                            mime="image/jpeg",
                            key="dl_refl_jpg",
                        )

    # Histogram box
    with st.container(border=True):
        st.markdown(t["hist_title"])
        st.write(t["hist_desc"])
        show_hist = st.button(t["btn_histogram"], key="btn_histogram", type="secondary")
        if show_hist:
            if original_img is not None:
                hist_fig = compute_histogram(original_img)
                st.pyplot(hist_fig)
                plt.close(hist_fig)
            else:
                st.warning(t["hist_warning"])

# ==================== RIGHT: IMAGE FILTERING ====================

with tools_col_right:
    with st.container(border=True):
        st.markdown(t["filter_title"])
        st.write(t["filter_desc"])
        st.markdown("---")

        # Tombol pilih filter
        filter_col1, filter_col2, filter_col3 = st.columns(3)
        with filter_col1:
            if st.button(t["btn_blur"], key="btn_blur_click", type="secondary"):
                st.session_state["image_filter"] = "blur"
        with filter_col2:
            if st.button(t["btn_sharpen"], key="btn_sharpen_click", type="secondary"):
                st.session_state["image_filter"] = "sharpen"
        with filter_col3:
            if st.button(t["btn_background"], key="btn_bg_click", type="secondary"):
                st.session_state["image_filter"] = "background"

        filter_col4, filter_col5, filter_col6 = st.columns(3)
        with filter_col4:
            if st.button(t["btn_grayscale"], key="btn_gray_click", type="secondary"):
                st.session_state["image_filter"] = "grayscale"
        with filter_col5:
            if st.button(t["btn_edge"], key="btn_edge_click", type="secondary"):
                st.session_state["image_filter"] = "edge"
        with filter_col6:
            if st.button(t["btn_brightness"], key="btn_bright_click", type="secondary"):
                st.session_state["image_filter"] = "brightness"

    # Box parameter filter di bawah tombol
    with st.container(border=True):
        if original_img is None:
            st.info(t["filter_info"])
        else:
            # BLUR
            if st.session_state["image_filter"] == "blur":
                st.markdown(t["blur_settings"])
                kernel_size = st.selectbox(
                    t["blur_kernel"],
                    [3, 5, 7],
                    index=0,
                    key="blur_kernel_size",
                )
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_blur", type="primary"):
                    gray = rgb_to_gray(original_img)
                    k = kernel_size
                    blur_kernel = np.ones((k, k), dtype=np.float32) / (k * k)
                    blurred_gray = manual_convolution_gray(gray, blur_kernel)
                    blurred_rgb = cv2.cvtColor(blurred_gray, cv2.COLOR_GRAY2RGB)
                    st.image(blurred_rgb, caption=t["blur_result"], use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(blurred_rgb, fmt="PNG"),
                            file_name="blur_result.png",
                            mime="image/png",
                            key="dl_blur_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(blurred_rgb, fmt="JPEG"),
                            file_name="blur_result.jpg",
                            mime="image/jpeg",
                            key="dl_blur_jpg",
                        )

            # SHARPEN
            elif st.session_state["image_filter"] == "sharpen":
                st.markdown(t["sharpen_settings"])
                st.write(t["sharpen_desc"])
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_sharpen", type="primary"):
                    gray = rgb_to_gray(original_img)
                    sharpen_kernel = np.array(
                        [[0, -1, 0],
                         [-1, 5, -1],
                         [0, -1, 0]],
                        dtype=np.float32,
                    )
                    sharpened_gray = manual_convolution_gray(gray, sharpen_kernel)
                    sharpened_rgb = cv2.cvtColor(sharpened_gray, cv2.COLOR_GRAY2RGB)
                    st.image(sharpened_rgb, caption=t["sharpen_result"], use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(sharpened_rgb, fmt="PNG"),
                            file_name="sharpen_result.png",
                            mime="image/png",
                            key="dl_sharp_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(sharpened_rgb, fmt="JPEG"),
                            file_name="sharpen_result.jpg",
                            mime="image/jpeg",
                            key="dl_sharp_jpg",
                        )

            # BACKGROUND
            elif st.session_state["image_filter"] == "background":
                st.markdown(t["bg_settings"])
                method = st.selectbox(
                    t["bg_method"],
                    [
                        "HSV Color Thresholding",
                        "Blur Background",
                        "Remove Background Transparent",
                        "Solid Red Background",
                        "Solid Blue Background",
                        "Solid Yellow Background",
                        "Solid Green Background",
                        "Solid Brown Background",
                    ],
                    key="bg_method",
                )
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_bg", type="primary"):
                    bg_removed_img = None
                    output_for_download = None
                    try:
                        if method == "HSV Color Thresholding":
                            bg_removed_img = simple_background_removal_hsv(original_img)
                            output_for_download = bg_removed_img
                        else:
                            if method == "Blur Background":
                                output_mode = "blurred"
                                solid_color = None
                            elif method == "Remove Background Transparent":
                                output_mode = "transparent"
                                solid_color = None
                            elif method == "Solid Red Background":
                                output_mode = "solid_color"
                                solid_color = (255, 0, 0)
                            elif method == "Solid Blue Background":
                                output_mode = "solid_color"
                                solid_color = (0, 0, 255)
                            elif method == "Solid Yellow Background":
                                output_mode = "solid_color"
                                solid_color = (255, 255, 0)
                            elif method == "Solid Green Background":
                                output_mode = "solid_color"
                                solid_color = (0, 255, 0)
                            elif method == "Solid Brown Background":
                                output_mode = "solid_color"
                                solid_color = (150, 75, 0)
                            else:
                                output_mode = "transparent"
                                solid_color = None

                            result = remove_background_advanced(
                                image=original_img,
                                mode="auto",
                                output_mode=output_mode,
                                solid_color=solid_color,
                                feather_radius=3,
                                refine_hair=True,
                            )
                            bg_removed_img = result
                            if result.ndim == 3 and result.shape[2] == 4:
                                output_for_download = result[:, :, :3]
                            else:
                                output_for_download = result
                    except Exception as e:
                        st.error(f"Error saat memproses background: {e}")
                        bg_removed_img = None
                        output_for_download = None

                    if bg_removed_img is not None:
                        st.image(bg_removed_img, caption=t["bg_result"], use_column_width=True)
                        col_png, col_jpg = st.columns(2)
                        with col_png:
                            st.download_button(
                                label="â¬‡ï¸ Download PNG",
                                data=image_to_bytes(output_for_download, fmt="PNG"),
                                file_name="background_result.png",
                                mime="image/png",
                                key="dl_bg_png",
                            )
                        with col_jpg:
                            st.download_button(
                                label="â¬‡ï¸ Download JPG",
                                data=image_to_bytes(output_for_download, fmt="JPEG"),
                                file_name="background_result.jpg",
                                mime="image/jpeg",
                                key="dl_bg_jpg",
                            )

            # GRAYSCALE
            elif st.session_state["image_filter"] == "grayscale":
                st.markdown(t["gray_settings"])
                st.write(t["gray_desc"])
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_gray", type="primary"):
                    gray_img = rgb_to_gray(original_img)
                    gray_rgb = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)
                    st.image(gray_rgb, caption=t["gray_result"], use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(gray_rgb, fmt="PNG"),
                            file_name="grayscale_result.png",
                            mime="image/png",
                            key="dl_gray_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(gray_rgb, fmt="JPEG"),
                            file_name="grayscale_result.jpg",
                            mime="image/jpeg",
                            key="dl_gray_jpg",
                        )

            # EDGE
            elif st.session_state["image_filter"] == "edge":
                st.markdown(t["edge_settings"])
                method_edge = st.selectbox(
                    t["edge_method"],
                    ["Sobel", "Canny"],
                    key="edge_method",
                )
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_edge", type="primary"):
                    img_bgr = to_opencv(original_img)
                    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                    if method_edge == "Sobel":
                        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
                        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
                        mag = cv2.magnitude(grad_x, grad_y)
                        mag = np.clip(mag, 0, 255).astype(np.uint8)
                        edge_bgr = cv2.cvtColor(mag, cv2.COLOR_GRAY2BGR)
                    else:
                        edges = cv2.Canny(gray, 100, 200)
                        edge_bgr = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
                    edge_img = to_streamlit(edge_bgr)
                    st.image(edge_img, caption=f"{t['edge_result']} ({method_edge})", use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(edge_img, fmt="PNG"),
                            file_name="edge_result.png",
                            mime="image/png",
                            key="dl_edge_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(edge_img, fmt="JPEG"),
                            file_name="edge_result.jpg",
                            mime="image/jpeg",
                            key="dl_edge_jpg",
                        )

            # BRIGHTNESS / CONTRAST
            elif st.session_state["image_filter"] == "brightness":
                st.markdown(t["bright_settings"])
                brightness = st.slider(t["bright_brightness"], -100, 100, 0, key="brightness_value")
                contrast = st.slider(t["bright_contrast"], -100, 100, 0, key="contrast_value")
                if st.button(f"{t['btn_apply']} âœ…", key="btn_apply_bright", type="primary"):
                    adjusted_img = adjust_brightness_contrast(original_img, brightness, contrast)
                    st.image(adjusted_img, caption=t["bright_result"], use_column_width=True)
                    col_png, col_jpg = st.columns(2)
                    with col_png:
                        st.download_button(
                            label="â¬‡ï¸ Download PNG",
                            data=image_to_bytes(adjusted_img, fmt="PNG"),
                            file_name="brightness_contrast_result.png",
                            mime="image/png",
                            key="dl_bright_png",
                        )
                    with col_jpg:
                        st.download_button(
                            label="â¬‡ï¸ Download JPG",
                            data=image_to_bytes(adjusted_img, fmt="JPEG"),
                            file_name="brightness_contrast_result.jpg",
                            mime="image/jpeg",
                            key="dl_bright_jpg",
                        )

# ===================== TEAM MEMBERS =====================

st.markdown(t["team_title"])
st.write(t["team_subtitle"])

members = [
    {"img": "images/gitsi.jpeg", "name": "Gita Sion Nauli Simatupang", "sid": "004202400055", "role": "Leader", "Contribution": "Project Manager, Geometric Transformations Module"},
    {"img": "images/bella.jpeg", "name": "Bella Amelia", "sid": "004202400050", "role": "Member", "Contribution": "Image Filtering Module, UI/UX Design"},
    {"img": "images/chinta.jpeg", "name": "Chinta Amanda Dwi Putri Carelina", "sid": "004202400035", "role": "Member", "Contribution": "Background Removal Module, Image Upload & Download"},
    {"img": "images/yessa.jpeg", "name": "Yessa Kireina Hanna Sevira", "sid": "004202400009", "role": "Member", "Contribution": "Histogram Module, Image Processing Functions"},
]

cols_row1 = st.columns(1, vertical_alignment="top")
for i in range(1):
    with cols_row1[i]:
        with st.container(border=True):
            m = members[i]
            safe_display_square_image(m["img"])
            # spasi vertikal kecil di bawah foto
            st.markdown("<div style='height:8px;'></div>", unsafe_allow_html=True)
            # teks di tengah
            st.markdown(
                f"<div style='text-align:center;'><strong>{m['name']}</strong></div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                f"<div style='text-align:center;'>{t['team_sid']} {m['sid']}</div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                f"<div style='text-align:center;'>{t['team_role']} {m['role']}</div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                f"<div style='text-align:center;'>{t['team_group']} 12</div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                f"<div style='text-align:center;'>{t['team_contribution']} {m['Contribution']}</div>",
                unsafe_allow_html=True,
            )

cols_row2 = st.columns(3, vertical_alignment="top")
for i in range(1, 4):
    with cols_row2[i - 1]:
        with st.container(border=True):
            m = members[i]
            safe_display_square_image(m["img"])
            st.markdown("<div style='height:8px;'></div>", unsafe_allow_html=True)
            st.markdown(
                f"<div style='text-align:center;'><strong>{m['name']}</strong></div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                f"<div style='text-align:center;'>{t['team_sid']} {m['sid']}</div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                f"<div style='text-align:center;'>{t['team_role']} {m['role']}</div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                f"<div style='text-align:center;'>{t['team_group']} 12</div>",
                unsafe_allow_html=True,
            )
            st.markdown(
                f"<div style='text-align:center;'>{t['team_contribution']} {m['Contribution']}</div>",
                unsafe_allow_html=True,
            )

